---
title: "TP 2"
author: "Miguel, Salvador y Thomas"
format: 
  html:
    self-contained: true
editor: source
---

## DATAFRAMES

Para este projecto disponemos de 2 Dataframes:

```{r  message=FALSE, warning=FALSE, include = FALSE}
source(file = "code.R", local = T)
load("tp2.Rdata")
```

<!--- Poner una visualización de ambos dataframes como en el tp1, y además explicar las nuevas variables creadas. --->

### Dataframe de Clima-EcoBici

```{r echo = FALSE}
kable(head(clima_ecobici_lluvia_dialaboral))
```

### Dataframe Fake News

```{r echo = FALSE}
kable(head(fake_news[, -which(names(fake_news) == "text")]), format = "html")
```

## LIBRERIAS

Para el TP usamos las siguientes librerias

```{r eval = FALSE}
library(ggplot2)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(parttree)
library(class)
library(readr)
library(knitr)
library(kableExtra)
```

<!--- Ponemos eval=F, include=F para evitar su ejecución puesto que estas librerías ya son ejecutadas en el archivo code.R --->

## REGRESIÓN

#### Problema

Buscamos hallar 2 variables que mejor describan/predigan el uso de bicis, según variables relacionadas al clima y fechas laborales.

#### Solución

Comenzaremos observando y haciendo un analisis exploratorio del dataframe. Este analísis tiene como objetivo encontrar las variables que mejor describan el uso de bicicletas en CABA.

Analizando cada variable independiente, observamos que una variable fue la que mejor se destaco en este analísis, la cual es "dia_laboral" que indica el uso de bicis en dias feriados/fines de semana y dias laborales.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_by_workdays
```

Con esta variable en consideración, analizamos como se comporta esta variable con las otras variables disponibles.

Hallamos 4 variables que podrían ser candidatos para ser la segunda variable. Éstas variables son tmin, tmax, tavg y llovio.

Los gráficos relacionados a la temperatura, son similares así que utilizaremos uno para representar todos.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_tavg_workday

gr_bike_uses_rain_workday 
```

Para decidir cual de las previas combinaciones de variables utilizar, llevamos a cabo una regresión lineal para cada combinación y calculamos el error cuadrático medio para 500 dataframes de testeo.

```{r}
gr_mean_squared_error_by_model
```

Mediante este gráfico se puede apreciar que las variables tavg(TempProm) y tmin(TempMin) presentan mejores valores de errores cuadráticos medios en comparación a tmax(TempMax) y los dias lluviosos. Dada la leve diferencia entre tavg y tmin, el modelo tavg-dia laboral presenta un error menor.\

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que apuntan a una mejor aproximación.
>
> $x_t$ : Representa la variables que indica el valor de la temperatura promedio (tavg)
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 indica que es día laboral y 0 indica que no es un día laboral.

Esta ecuación representa dos parabolas, ecuaciones cuadraticas, cuya diferencia es el desplazamiento en el eje y.

```{r}
gr_visualizacion_modelotavg
```

Aquí nos propusimos intentar de hallar una ecuacion que mejor describa el modelo aun.

<!--- AGREGAR ECUACION DEL TAVG-DIALABMEJORADO --->

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l + \beta_4 . x_t . x_t^2 + \beta_5 . x_t . x_l + \beta_6 . x_t^2 . x_l + \beta_7 . x_t . x_t^2 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que apuntan a una mejor aproximación.
>
> $x_t$ : Representa la variables que indica el valor de la temperatura promedio (tavg)
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 indica que es día laboral y 0 indica que no es un día laboral.

Esta ecuación representa dos ecuaciones de grado 3, cuya diferencia es el desplazamiento y la amplitud de cada función.

```{r}
gr_visualizacion_modelotavg_mejorado
```

Según el gráfico podemos notar que la diferencia recae en mayor medida en los dias no laborales, por ende, encontramos una predicción mucho mejor para este tipo de casos.

```{r}
gr_mean_squared_error_tavg_upgrade_model
```

Nuevamente notamos que el error es un poco menor, por ende, utilizaremos esta mejora del tavg para predecir nuevos datos.

```{r message=FALSE, warning=FALSE}
gr_quadratic_ecuation_model
gr_bike_uses_tavg_workday
```

Mediante este último cuadro, podemos evidenciar la similitud relativa que presenta el modelo con el comportamiento real de los datos.

#### Conclusión

------------------------------------------------------------------------

## CLASIFICACIÓN

#### Problema

El objetivo de este ejercicio es desarrollar un clasificador de noticias en "reales" o "fake-news". A partir de 3 predictores definidos: `title_has_excl, negative y title_words.`

#### Solución

Comenzamos visualizando las variables predictoras para ver si pueden sesr útiles para clasificar las noticias en "reales" vs. "fake-news".

```{r}
table_fakenews_excl

gr_negative_title_words
```

Notamos que las variables mencionadas tienen cierta habilidad para predecir si una noticia es real o fake. A partir de este analisis exploratorio, podemos observar una notoria tendencia en la veracidad de las noticias, a medida que el porcentaje de palabras negativas en los títulos y la cantidad de palabras que lo componen también es menor, hay una mayor concentración de noticias reales. En el resto de los cuadrantes observados en el gráfico, existe una mayor predominancia de noticias falsas.

Con esta información, ahora trabajaremos para crear dos modelos que puedan predecir que probabilidad tiene una noticia de ser fake o real, en base a estás variables.

### Modelo de Árboles de Decisión

Para nuestro modelo de árboles de decisión, debemos hallar el minsplit que mejor predice la variable type

```{r}
head(v_accuracy_prom_tree, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)

```

Vemos que para varios testeos un minsplit con valor 28, fue el que mejor predijo en promedio.

#probar con mas tests y ver otras variables (investigar rpart.control())

```{r}
rpart.plot(tree_model, shadow.col = "#C8B596", box.palette = "Browns", tweak = 1.2, extra = 8)
```

<!--- PONER EL ACCURACY Y CREAR LA MATRIZ DE CONFUSION --->

```{r}
kable(table_matriz_de_confusion_tree)

kable(v_accuracy_prom_tree[1,], digits = 3)
```

### Modelo de K-NN

Para nuestro modelo de k-nn, debemos hallar el k que mejor predice la variable type

```{r}
head(v_accuracy_prom_knn, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)
```

Vemos que para 15 testeos un k con valor 31, fue el que mejor predijo en promedio.

<!--- probar con mas tests y ver otras variables (investigar rpart.control()) --->

<!--- agregar un geom_point para mostrar las predicciones--->

<!--- agregar matriz de confusion y accuracy --->

```{r}
kable(table_matriz_de_confusion_knn, digits = 3)
```

#### Testeo

Supongamos que se publica un nuevo artículo que tiene un título de 15 palabras sin signos de exclamación y el 6% de sus palabras tienen connotaciones negativas. Calcular la probabilidad de que el artículo sea "fake-news".

Probemos con nuestos modelos la probabilidad de que sea real vs fake.

```{r}

kable(prediction_tree_model, digits = 3)


prediction_knn_model

```

#### Conclusión
