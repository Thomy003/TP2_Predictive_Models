---
title: "TP 2"
author: "Miguel, Salvador y Thomas"
format: 
  html:
    self-contained: true
editor: source
---

## DATAFRAMES

Para este projecto disponemos de 2 Dataframes que se nos han proporcionado:

```{r  message=FALSE, warning=FALSE, include = FALSE}
source(file = "code.R", local = T)
load("tp2.Rdata")
```

<!--- Poner una visualización de ambos dataframes como en el tp1, y además explicar las nuevas variables creadas. --->

### Dataframe de Clima-EcoBici

```{r echo = FALSE}
kable(head(clima_ecobici_lluvia_dialaboral))
```

### Dataframe Fake News

```{r echo = FALSE}
kable(head(fake_news[, -which(names(fake_news) == "text")]), format = "html")
```

## LIBRERIAS

Para el TP usamos las siguientes librerias

```{r eval = FALSE}
library(ggplot2)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(parttree)
library(class)
library(readr)
library(knitr)
library(kableExtra)
```

<!--- Ponemos eval=F, include=F para evitar su ejecución puesto que estas librerías ya son ejecutadas en el archivo code.R --->

## REGRESIÓN

#### Problema

Buscamos hallar 2 variables que mejor describan/predigan el uso de bicis, a partir de las variables que se observan en el primer dataframe, relacionadas al clima y a las fechas laborales.

#### Solución

Comenzaremos observando y haciendo un analisis exploratorio del dataframe. Este analísis tiene como objetivo encontrar las variables que mejor describan el uso de bicicletas en CABA.

Analizando cada variable independientemente, observamos que la variable `dia_laboral` fue la que mejor se destacó en este analísis, lo cual indica que el uso de bicis en días feriados o fines de semana es mucho menor comparado a los días laborales.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_by_workdays
```

Entonces vamos a tomar `dia_laboral` como candidata a variable predictoria, ahora analizaremos como se comporta está variable con relación a las otras variables disponibles.

Tras otro analisís hallamos que hay 4 variables que podrían ser candidatas para ser la segunda variable predictoria. Éstas variables son `tmin` , `tmax` , `tavg` y `llovio`.

::: callout-note
Los gráficos relacionados a la temperatura, son similares así que utilizaremos uno para representar la idea general.
:::

```{r message=FALSE, warning=FALSE}
gr_bike_uses_tavg_workday

gr_bike_uses_rain_workday 
```

Para decidir cual de las previas combinaciones de variables utilizar como variables predictorias, llevamos a cabo una modelación de regresión lineal para cada combinación, y con ella calculamos el error cuadrático medio para 300 dataframes de testeo distintos.

```{r}
gr_mean_squared_error_by_model
```

Mediante este gráfico se puede apreciar que las variables `tavg` (TempProm) y `tmin` (TempMin) presentan mejores valores de errores cuadráticos medios en comparación a `tmax` (TempMax) y `llovio` (días lluviosos). Dada la leve diferencia entre `tavg` y `tmin` , el modelo `tavg-dia_laboral` presenta un error menor.\

#### Ecuación del Modelo de Regresión Lineal

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos parabolas, ecuaciones cuadraticas, cuya diferencia es el desplazamiento en el eje y.

```{r}
gr_visualizacion_modelotavg
```

#### Ecuación del Modelo de Regresión Lineal Mejorado

Jugando con el modelo de regresión, notamos que hay una ecuación que describe un poco mejor el uso de bicis. Esta nueva ecuación, a comparación de la anterior, involucra una relación entre cada variable.

<!--- AGREGAR ECUACION DEL TAVG-DIALABMEJORADO --->

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l + \beta_4 . x_t . x_t^2 + \beta_5 . x_t . x_l + \beta_6 . x_t^2 . x_l + \beta_7 . x_t . x_t^2 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos ecuaciones de grado 3, cuya diferencia es el desplazamiento y la amplitud de cada función.

```{r}
gr_visualizacion_modelotavg_mejorado
```

Según el gráfico del modelo podemos notar que la diferencia entre este gráfico y el anterior recae en la curva que explica el uso de bicis para los dias no laborales.

Para estar seguros de que esta nueva ecuación es mejor que la anterior, corrimos unos casos tests a los cuales les calculamos el error cuadrático medio.

```{r}
gr_mean_squared_error_tavg_upgrade_model
```

Nuevamente notamos que el error es un poco menor con esta última ecuación, por ende, utilizaremos dichas ecuación para predecir nuevos datos. , y también podemos afirmar que encontramos una predicción mucho mejor para los datos que pertenecen a días no laborales como se ve en los siguientes gráficos.

```{r message=FALSE, warning=FALSE}
gr_quadratic_ecuation_model
gr_bike_uses_tavg_workday
```

Mediante este último cuadro, podemos evidenciar la similitud relativa que presenta el modelo con el comportamiento real de los datos.

#### Conclusión

Podemos concluir que luego de analizar la oscilación en el uso de Ecobicis dependiendo de distintas variables, concluimos que las dos variables que mejor pueden predecir el uso de bicis son: `tavg` y `dia_laboral` , siendo este último el que generaba el cambio más significativo.

------------------------------------------------------------------------

## CLASIFICACIÓN

#### Problema

El objetivo de este ejercicio es desarrollar un clasificador de noticias en "reales" o "fake-news". A partir de 3 predictores definidos: `title_has_excl, negative y title_words.`

#### Solución

Comenzamos visualizando el comportamiento de las variables predictoras con respecto al tipo de noticas, para ver si pueden ser útiles para clasificar las noticias en "reales" o "fake-news", es decir si pueden influir en la veracidad de la noticia.

```{r echo = FALSE}
kable(table_fakenews_excl)
```

```{r}
gr_negative_title_words
```

Notamos que las variables mencionadas tienen cierta habilidad para predecir si una noticia es real o fake. A partir de este analisis exploratorio, podemos observar una notoria tendencia en la veracidad de las noticias, a medida que el porcentaje de palabras negativas en los títulos y la cantidad de palabras que lo componen es menor, hay una mayor concentración mayoritaria de noticias reales. En el resto de los cuadrantes observados en el gráfico, existe una mayor predominancia de noticias falsas, exceptuando por una porción extra.

Además, el uso de signos de exclamación también influye de tal manera que una aparición de estos, muestra un aumento en la probabilidad de que la noticia sea fake.

Con esta información, ahora trabajaremos para crear dos modelos que puedan predecir que probabilidad tiene una noticia de ser fake o real, en base a estás variables.

### Modelo de Árboles de Decisión

Para nuestro modelo de árboles de decisión, debemos hallar el minsplit (mínima cantidad de observaciones para birfucar) que mejor predice la variable type.

```{r}
head(v_accuracy_prom_tree, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)

```

Vemos que para varios testeos un minsplit de 28 o 29, son los que mejor predicen en promedio. Nosotros optamos por elegir 28.

<!--- probar con mas tests y ver otras variables (investigar rpart.control()) --->

Con un minsplit de 28, el árbol de decisión nos queda de la siguiente manera:

```{r}
rpart.plot(tree_model, shadow.col = "#C8B596", box.palette = "Browns", tweak = 1.2, extra = 8)
```

Un color marrón denota que la noticia tiene una mayor probabilidad de ser real, mientras que un color blanco indica que la noticia tiene mayor probabilidad de ser falsa. Los números bajo los tags (real o fake), señalan la probabilidad de que una noticia pertenezca a dicho tag

<!--- PONER EL ACCURACY Y CREAR LA MATRIZ DE CONFUSION --->

A continuación indicamos la matriz de confusión para un caso de testeo.

```{r}
kable(table_matriz_de_confusion_tree)
```

### Modelo de K-NN

A continuación, para nuestro modelo de k-nn, debemos hallar el k (cantidad de observaciones más cercanas con las que comparar) que mejor predice la variable type.

```{r}
head(v_accuracy_prom_knn, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)
```

Vemos que para varios testeos un k con valor 31, es el que mejor predice en promedio. Vale aclarar, que previamente analizamos todos los casos individuales para evitar outliers y que el promedio se vea distorcionado.

<!--- probar con mas tests y ver otras variables (investigar rpart.control()) --->

<!--- agregar un geom_point para mostrar las predicciones--->

<!--- agregar matriz de confusion y accuracy --->

```{r}
kable(table_matriz_de_confusion_knn, digits = 3)
```

#### Testeo

Para probar nuestros modelos vamos a suponer que se publica un nuevo artículo que tiene un título de 15 palabras sin signos de exclamación y el 6% de sus palabras tienen connotaciones negativas. Calcular la probabilidad de que el artículo sea "fake-news".

Probemos con nuestos modelos cúal es la probabilidad de que esta noticia sea real o fake.

##### Modelo árbol de decisión:

```{r echo = FALSE}

cat("Probability Fake New:", round(prediction_tree_model[,1] * 100, digits = 1), "%\n")
cat("Probability Real New:", round(prediction_tree_model[,2] * 100, digits = 1), "%\n")

```

##### Modelo K-NN:

```{r echo = FALSE}
cat("Probability Fake New:", round(probability * 100, digits = 1), "%\n")
cat("Probability Real New:", 100 - round(probability * 100, digits = 1), "%\n")
```

#### Conclusión

Si bien ambos modelos de predicción presentan una precisión alrededor de los 65/66%, es importante destacar que este nivel de exactitud, podría no ser completamente fiable para determinar con seguridad si una noticia es real o falsa. El hecho de que ambos modelos tengan un margen de error amplio sugiere que hay cierta incertidumbre en las predicciones.

De todas formas estos modelos pueden ser valiosos como una herramienta inicial para evaluar la autenticidad de una noticia. La precisión del 66% proporciona una indicación útil para realizar una primera evaluación.

En resumen, estos modelos son una buena herramienta de detección inicial, pero no deben ser el único criterio para clasificar una noticia como real o falsa.
