---
title: "TP 2"
author: "Miguel, Salvador y Thomas"
format: 
  html:
    self-contained: true
editor: source
---

## DATAFRAMES

Para este projecto disponemos de 2 Dataframes:

```{r  message=FALSE, warning=FALSE, include = FALSE}
source(file = "code.R", local = T)
load("tp2.Rdata")
```

<!--- Poner una visualización de ambos dataframes como en el tp1, y además explicar las nuevas variables creadas. --->

### Dataframe de Clima-EcoBici

```{r echo = FALSE}
kable(head(clima_ecobici_lluvia_dialaboral))
```

### Dataframe Fake News

```{r echo = FALSE}
kable(head(fake_news[, -which(names(fake_news) == "text")]), format = "html")
```

## LIBRERIAS

Para el TP usamos las siguientes librerias

```{r eval = FALSE}
library(ggplot2)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(parttree)
library(class)
library(readr)
library(knitr)
library(kableExtra)
```

<!--- Ponemos eval=F, include=F para evitar su ejecución puesto que estas librerías ya son ejecutadas en el archivo code.R --->

## REGRESIÓN

#### Problema

Buscamos hallar 2 variables que mejor describan/predigan el uso de bicis, a partir de las variables que se observan en el primer dataframe, relacionadas al clima y a las fechas laborales.

#### Solución

Comenzaremos observando y haciendo un analisis exploratorio del dataframe. Este analísis tiene como objetivo encontrar las variables que mejor describan el uso de bicicletas en CABA.

Analizando cada variable independientemente, observamos que la variable `dia_laboral` fue la que mejor se destacó en este analísis, lo cual indica que el uso de bicis en días feriados o fines de semana es mucho menor comparado a los días laborales.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_by_workdays
```

Entonces vamos a tomar `dia_laboral` como candidata a variable predictoria, ahora analizaremos como se comporta está variable con relación a las otras variables disponibles.

Tras otro analisís hallamos que hay 4 variables que podrían ser candidatas para ser la segunda variable predictoria. Éstas variables son `tmin` , `tmax` , `tavg` y `llovio`.

::: callout-note
Los gráficos relacionados a la temperatura, son similares así que utilizaremos uno para representar la idea general.
:::

```{r message=FALSE, warning=FALSE}
gr_bike_uses_tavg_workday

gr_bike_uses_rain_workday 
```

Para decidir cual de las previas combinaciones de variables utilizar como variables predictorias, llevamos a cabo una modelación de regresión lineal para cada combinación, y con ella calculamos el error cuadrático medio para 300 dataframes de testeo distintos.

```{r}
gr_mean_squared_error_by_model
```

Mediante este gráfico se puede apreciar que las variables `tavg` (TempProm) y `tmin` (TempMin) presentan mejores valores de errores cuadráticos medios en comparación a `tmax` (TempMax) y `llovio` (días lluviosos). Dada la leve diferencia entre `tavg` y `tmin` , el modelo `tavg-dia_laboral` presenta un error menor.\

#### Ecuación del Modelo de Regresión Lineal

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos parabolas, ecuaciones cuadraticas, cuya diferencia es el desplazamiento en el eje y.

```{r}
gr_visualizacion_modelotavg
```

#### Ecuación del Modelo de Regresión Lineal Mejorado

Jugando con el modelo de regresión, notamos que hay una ecuación que describe un poco mejor el uso de bicis. Esta nueva ecuación, a comparación de la anterior, involucra una relación entre cada variable.

<!--- AGREGAR ECUACION DEL TAVG-DIALABMEJORADO --->

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l + \beta_4 . x_t . x_t^2 + \beta_5 . x_t . x_l + \beta_6 . x_t^2 . x_l + \beta_7 . x_t . x_t^2 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos ecuaciones de grado 3, cuya diferencia es el desplazamiento y la amplitud de cada función.

```{r}
gr_visualizacion_modelotavg_mejorado
```

Según el gráfico del modelo podemos notar que la diferencia entre este gráfico y el anterior recae en la curva que explica el uso de bicis para los dias no laborales.

Para estar seguros de que esta nueva ecuación es mejor que la anterior, corrimos unos casos tests a los cuales les calculamos el error cuadrático medio.

```{r}
gr_mean_squared_error_tavg_upgrade_model
```

Nuevamente notamos que el error es un poco menor con esta última ecuación, por ende, utilizaremos dichas ecuación para predecir nuevos datos. , y también podemos afirmar que encontramos una predicción mucho mejor para los datos que pertenecen a días no laborales como se ve en los siguientes gráficos.

```{r message=FALSE, warning=FALSE}
gr_quadratic_ecuation_model
gr_bike_uses_tavg_workday
```

Mediante este último cuadro, podemos evidenciar la similitud relativa que presenta el modelo con el comportamiento real de los datos.

#### Conclusión

Podemos concluir que mediante un analisís exploratorio las dos variables que mejor pueden predecir el uso de bicis son: `tavg` y `dia_laboral` , pues sus errores son los que menor magnitud tenían. Aún así, quizás utilizando más variables podriamos llegar a descubrir un modelo con mejor precisión.

------------------------------------------------------------------------

## CLASIFICACIÓN

#### Problema

El objetivo de este ejercicio es desarrollar un clasificador de noticias en "reales" o "fake-news". A partir de 3 predictores definidos: `title_has_excl, negative y title_words.`

#### Solución

Comenzamos visualizando las variables predictoras para ver si pueden sesr útiles para clasificar las noticias en "reales" vs. "fake-news".

```{r echo = FALSE}
kable(table_fakenews_excl)
```

```{r}
gr_negative_title_words
```

Notamos que las variables mencionadas tienen cierta habilidad para predecir si una noticia es real o fake. A partir de este analisis exploratorio, podemos observar una notoria tendencia en la veracidad de las noticias, a medida que el porcentaje de palabras negativas en los títulos y la cantidad de palabras que lo componen también es menor, hay una mayor concentración de noticias reales. En el resto de los cuadrantes observados en el gráfico, existe una mayor predominancia de noticias falsas.

Con esta información, ahora trabajaremos para crear dos modelos que puedan predecir que probabilidad tiene una noticia de ser fake o real, en base a estás variables.

### Modelo de Árboles de Decisión

Para nuestro modelo de árboles de decisión, debemos hallar el minsplit que mejor predice la variable type

```{r}
head(v_accuracy_prom_tree, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)

```

Vemos que para varios testeos un minsplit con valor 28, fue el que mejor predijo en promedio.

#probar con mas tests y ver otras variables (investigar rpart.control())

```{r}
rpart.plot(tree_model, shadow.col = "#C8B596", box.palette = "Browns", tweak = 1.2, extra = 8)
```

<!--- PONER EL ACCURACY Y CREAR LA MATRIZ DE CONFUSION --->

```{r}
kable(table_matriz_de_confusion_tree)

kable(v_accuracy_prom_tree[1,], digits = 3)
```

### Modelo de K-NN

Para nuestro modelo de k-nn, debemos hallar el k que mejor predice la variable type

```{r}
head(v_accuracy_prom_knn, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)
```

Vemos que para 15 testeos un k con valor 31, fue el que mejor predijo en promedio.

<!--- probar con mas tests y ver otras variables (investigar rpart.control()) --->

<!--- agregar un geom_point para mostrar las predicciones--->

<!--- agregar matriz de confusion y accuracy --->

```{r}
kable(table_matriz_de_confusion_knn, digits = 3)
```

#### Testeo

Supongamos que se publica un nuevo artículo que tiene un título de 15 palabras sin signos de exclamación y el 6% de sus palabras tienen connotaciones negativas. Calcular la probabilidad de que el artículo sea "fake-news".

Probemos con nuestos modelos la probabilidad de que sea real vs fake.

```{r}

kable(prediction_tree_model, digits = 3)


prediction_knn_model

```

#### Conclusión
