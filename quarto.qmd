---
title: "TP 2"
author: "Miguel Avedaño, Salvador de Vedia y Thomas Castagnola"
format: 
  html:
    self-contained: true
editor: source
---

## DATAFRAMES

Para este projecto disponemos de 2 Dataframes que se nos han sido proporcionados:

```{r  message=FALSE, warning=FALSE, include = FALSE}
source(file = "code.R", local = T)
load("tp2.Rdata")
```

<!--- Poner una visualización de ambos dataframes como en el tp1, y además explicar las nuevas variables creadas. --->

### Dataframe de Clima-EcoBici

```{r echo = FALSE}
kable(head(clima_ecobici_lluvia_dialaboral))
```

### Dataframe Fake News

```{r echo = FALSE}
kable(head(fake_news[, -which(names(fake_news) == "text")]), format = "html")
```

## LIBRERIAS

Para el TP usamos las siguientes librerias

```{r eval = FALSE}
library(ggplot2)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(parttree)
library(class)
library(readr)
library(knitr)
library(kableExtra)
```

<!--- Ponemos eval=F, include=F para evitar su ejecución puesto que estas librerías ya son ejecutadas en el archivo code.R --->

## REGRESIÓN

#### Problema

Buscamos hallar 2 variables que mejor describan/predigan el uso de bicis, a partir de las variables que se observan en el primer dataframe.

#### Solución

Comenzaremos observando y haciendo un análisis exploratorio del dataframe. Este análisis tiene como objetivo encontrar las variables que mejor describan el uso de bicicletas en CABA.

Analizando cada variable independientemente, observamos que la variable `dia_laboral` fue la que mejor se destacó en este análisis, lo cual indica que el uso de bicis en días feriados o fines de semana es mucho menor comparado a los días laborales.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_by_workdays
```

Entonces vamos a tomar `dia_laboral` como candidata a variable predictora, ahora analizaremos como se comporta está variable con relación a las otras variables disponibles.

Tras otro análisis hallamos que hay 4 variables que podrían ser candidatas para ser la segunda variable predictora. Estas variables son `tmin` , `tmax` , `tavg` y `llovio`.

::: callout-note
Los gráficos relacionados a la temperatura, son similares así que utilizaremos uno para representar la idea general.
:::

```{r message=FALSE, warning=FALSE}
gr_bike_uses_tavg_workday

gr_bike_uses_rain_workday 
```

Para decidir cuál de las previas combinaciones vamos utilizar como variables predictoras, llevamos a cabo una modelación de regresión lineal para cada combinación, y con ella calculamos el error cuadrático medio para 300 dataframes de testeo distintos.

```{r}
gr_mean_squared_error_by_model
```

Mediante este gráfico se puede apreciar que las variables `tavg` (TempProm) y `tmin` (TempMin) presentan mejores valores de errores cuadráticos medios en comparación a `tmax` (TempMax) y `llovio` (días lluviosos). Dada la leve diferencia entre `tavg` y `tmin` , el modelo `tavg-dia_laboral` presenta un error menor.\

#### Ecuación del Modelo de Regresión Lineal

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos parábolas, ecuaciones cuadráticas, cuya diferencia es el desplazamiento en el eje y.

```{r}
gr_visualizacion_modelotavg
```

#### Ecuación del Modelo de Regresión Lineal Mejorado

Jugando con el modelo de regresión, notamos que hay una ecuación que describe un poco mejor el uso de bicis. Esta nueva ecuación, a comparación de la anterior, involucra una relación entre cada variable.

<!--- AGREGAR ECUACION DEL TAVG-DIALABMEJORADO --->

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l + \beta_4 . x_t . x_t^2 + \beta_5 . x_t . x_l + \beta_6 . x_t^2 . x_l + \beta_7 . x_t . x_t^2 . x_l 
$$

> $\alpha$ : Representa el intercept (ordenada al origen)
>
> $\beta_1 , \beta_2 , \beta_3$ : Representan los coeficientes calculados por el modelo, que mejor describen las curvas de aproximación.
>
> $x_t$ : Es la variable que toma el valor de la temperatura promedio `tavg`
>
> $x_l$ : Representa una variable dummy que toma dos valores, 1 si es día laboral y 0 si no es un día laboral.

Esta ecuación representa dos ecuaciones de grado 3, cuya diferencia es el desplazamiento y la amplitud de cada función.

```{r}
gr_visualizacion_modelotavg_mejorado
```

Según el gráfico del modelo podemos notar que la diferencia entre este gráfico y el anterior recae en la curva que explica el uso de bicis para los días no laborales.

Para estar seguros de que esta nueva ecuación es mejor que la anterior, corrimos unos casos tests a los cuales les calculamos el error cuadrático medio.

```{r}
gr_mean_squared_error_tavg_upgrade_model
```

Nuevamente, notamos que el error es un poco menor con esta última ecuación, por ende, utilizaremos dicha ecuación para predecir nuevos datos.

Podemos afirmar que encontramos una predicción mejor para los datos que pertenecen a días no laborales, como se ve en los siguientes gráficos.

```{r message=FALSE, warning=FALSE}
gr_quadratic_ecuation_model
gr_bike_uses_tavg_workday
```

Mediante este último cuadro, podemos evidenciar la similitud relativa que presenta el modelo con el comportamiento real de los datos.

#### Conclusión

Podemos concluir que luego de analizar la oscilación en el uso de Ecobicis dependiendo de distintas variables, las dos variables que mejor pueden predecir el uso de bicis son: `tavg` y `dia_laboral` , siendo este último el que generaba el cambio más significativo.

------------------------------------------------------------------------

## CLASIFICACIÓN

#### Problema

El objetivo de este ejercicio es desarrollar un clasificador de noticias en "reales" o "fake-news". A partir de 3 predictores definidos: `title_has_excl, negative y title_words.`

#### Solución

Comenzamos visualizando el comportamiento de las variables predictoras con respecto al tipo de noticias, para ver si pueden ser útiles para clasificar las noticias en "reales" o "fake-news", es decir, si pueden influir en la veracidad de la noticia.

```{r echo = FALSE}
kable(table_fakenews_excl)
```

Observamos el uso de signos de exclamación influye de tal manera que una aparición de estos, muestra un gran aumento en la probabilidad de que la noticia sea fake.

```{r}
gr_negative_title_words
```

En este otro gráfico, notamos que a medida que el porcentaje de palabras negativas en los títulos y la cantidad de palabras que lo componen es menor, hay una mayor concentración de noticias reales. En el resto de los cuadrantes, existe una mayor predominancia de noticias falsas, exceptuando por una porción extra.

Finalmente podes afirmar que las variables mencionadas tienen cierta habilidad para predecir si una noticia es real o fake.

Con esta información, ahora trabajaremos para crear dos modelos que puedan predecir que probabilidad tiene una noticia de ser fake o real.

### Modelo de Árboles de Decisión

Para nuestro modelo de árboles de decisión, debemos hallar el minsplit (mínima cantidad de observaciones para birfurcar) que mejor predice la variable type.

```{r echo = FALSE}
head(v_accuracy_prom_tree, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)

```

Vemos que para varios testeos, un minsplit de 28 o 29, son los que mejor predicen en promedio. Nosotros optamos por elegir 28.

<!--- probar con mas tests y ver otras variables (investigar rpart.control()) --->

Con un minsplit de 28, el árbol de decisión nos queda de la siguiente manera:

```{r echo = FALSE}
rpart.plot(tree_model, shadow.col = "#C8B596", box.palette = "Browns", tweak = 1.2, extra = 8)
```

Un color marrón denota que la noticia tiene una mayor probabilidad de ser real, mientras que un color blanco indica que la noticia tiene mayor probabilidad de ser falsa. Los números bajo los tags (real o fake), señalan la probabilidad de que una noticia pertenezca a dicho tag.

<!--- PONER EL ACCURACY Y CREAR LA MATRIZ DE CONFUSION --->

A continuación indicamos la matriz de confusión para un caso de testeo.

```{r echo=FALSE}
kable(table_matriz_de_confusion_tree)
```

### Modelo de K-NN

A continuación, para nuestro modelo de k-nn, debemos hallar el k (cantidad de observaciones más cercanas con las que comparar) que mejor predice la variable type.

```{r echo=FALSE}
head(v_accuracy_prom_knn, n = 10) %>% 
  kbl(digits = 3) %>% 
  kable_paper("hover", 
              full_width = F)
```

Vemos que para varios testeos un k con valor 31, es el que mejor predice en promedio. Vale aclarar, que previamente analizamos todos los casos individuales para evitar outliers y que el promedio se vea distorsionado.

```{r echo = FALSE}
kable(table_matriz_de_confusion_knn, digits = 3)
```

#### Testeo

Para probar nuestros modelos vamos a suponer que se publica un nuevo artículo que tiene un título de 15 palabras sin signos de exclamación y el 6% de sus palabras tienen connotaciones negativas. Calcular la probabilidad de que el artículo sea "fake-news".

Veamos cúal es la probabilidad de que esta noticia sea real o fake según los modelos

##### Modelo árbol de decisión:

```{r echo = FALSE}

cat("Probability Fake New:", round(prediction_tree_model[,1] * 100, digits = 1), "%\n")
cat("Probability Real New:", round(prediction_tree_model[,2] * 100, digits = 1), "%\n")

```

##### Modelo K-NN:

```{r echo = FALSE}
cat("Probability Fake New:", round(probability * 100, digits = 1), "%\n")
cat("Probability Real New:", 100 - round(probability * 100, digits = 1), "%\n")
```

#### Conclusión

Si bien ambos modelos de predicción presentan una precisión alrededor del 66%, es importante destacar que este nivel de exactitud, podría no ser completamente fiable para determinar con seguridad si una noticia es real o falsa. El hecho de que ambos modelos tengan un margen de error amplio sugiere que hay cierta incertidumbre en las predicciones.

De todas formas, estos modelos pueden ser valiosos como una herramienta inicial para evaluar la autenticidad de una noticia. La precisión del 66% proporciona una indicación útil para realizar una primera evaluación.

En resumen, estos modelos son una buena herramienta de detección inicial, pero no deben ser el único criterio para clasificar una noticia como real o falsa.
