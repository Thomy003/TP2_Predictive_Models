---
title: "tp2"
author: "Miguel, Salvador, Thomas"
format: 
  html:
    self-contained: true
editor: source
---

## DATAFRAMES

```{r message=FALSE, warning=FALSE, include = FALSE}
source(file = "code.R", local = T)
load("tp2.Rdata")
```

<!--- Poner una visualización de ambos dataframes como en el tp1, y además explicar las nuevas variables creadas. --->

### Dataframe de Clima-EcoBici

```{r echo = FALSE}
kable(head(clima_ecobici_lluvia_dialaboral))
```

### Dataframe Fake News

```{r echo = FALSE}
kable(head(fake_news[, -which(names(fake_news) == "text")]), format = "html")
```

## LIBRERIAS

Para el tp usamos las siguientes librerias

```{r eval = FALSE}
library(ggplot2)
library(tidyverse)
library(rpart)
library(rpart.plot)
library(parttree)
library(class)
library(readr)
library(knitr)
```

<!--- Ponemos eval=F, include=F para evitar su ejecución puesto que estas librerías ya son ejecutadas en el archivo code.R --->

## REGRESIÓN

#### Problema

Buscamos hallar 2 variables que mejor describan/predigan el uso de bicis. En base a los resultados obtenidos en el desarrollo del TP1, consideramos como mejores posibles variables auxiliares aquellas que estén relacionadas con el clima y con los días laborales.

#### Solución

Comenzaremos observando y haciendo un analisis exploratorio del dataframe. Este analísis tiene como objetivo encontrar las variables que mejor describan el uso de bicicletas en CABA.

Analizando cada variable independiente, observamos que una opción fue la que mejor se destaco en este analísis, la cual es "dia_laboral" que indica el uso de bicis en dias feriados/fines de semana y dias laborales.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_by_workdays
```

Con esta variable en consideración, analizamos como se comporta esta variable con las otras variables disponibles.

Hallamos 4 variables que podrían ser candidatos para ser la segunda variable. Éstas son tmin, tmax, tavg y días lluviosos.

Los gráficos relacionados a la temperatura, son similares así que utilizaremos uno para representar todos.

```{r message=FALSE, warning=FALSE}
gr_bike_uses_tavg_workday

gr_bike_uses_rain_workday 
```

Para decidir cual de las previas combinaciones de variables utilizar, llevamos a cabo una regresión lineal para cada combinación y calculamos el error cuadrático medio para 500 dataframes de testeo.

```{r}
gr_mean_squared_error_by_model
```

Mediante este gráfico se puede apreciar que las variables tavg(TempProm) y tmin(TempMin) presentan mejores valores de errores cuadráticos medios en comparación a tmax(TempMax) y los dias laborales lluviosos. Dada la leve diferencia entre tavg y tmin, tavg y día laboral presentan un mejor modelo.

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l 
$$

-   $\alpha$ es el intercept

-   Los $\beta$ son coeficientes calculados por el modelo, que apuntan a una mejor aproximación.

-   $x_t$ es la variable que indica el valor de la temperatura promedio (tavg)

-   $x_l$ es una variable dummy que vale 1 si es dia laboral y 0 si es un día no laboral

Esta ecuación representa dos parabolas, ecuaciones cuadraticas, cuya diferencia es el desplazamiento en el eje y.

```{r}
gr_visualizacion_modelotavg
```

Aquí nos propusimos intentar de hallar una ecuacion que mejor describa el modelo aun.

#AGREGAR ECUACION DEL TAVG-DIALABMEJORADO

$$
y = \alpha + \beta_1 . x_t + \beta_2 . x_t^2 + \beta_3 . x_l + \beta_4 . x_t . x_t^2 + \beta_5 . x_t . x_l + \beta_6 . x_t^2 . x_l + \beta_7 . x_t . x_t^2 . x_l 
$$

-   $\alpha$ es el intercept

-   Los $\betas$ son coeficientes calculados por el modelo, que apuntan a una mejor aproximación.

-   $x_t$ es la variable que indica el valor de la temperatura promedio (tavg)

-   $x_l$ es una variable dummy que si vale 1 indica que es dia laboral y 0 que no es un dia laboral

Esta ecuación representa dos ecuaciones de grado 3, cuya diferencia es el desplazamiento y la amplitud de cada función.

```{r}
gr_visualizacion_modelotavg_mejorado
```

Según el gráfico podemos notar que la diferencia recae en mayor medida en los dias no laborales, por ende, encontramos una predicción mucho mejor para este tipo de casos.

```{r}
gr_mean_squared_error_tavg_upgrade_model
```

Nuevamente notamos que el error es un poco menor, por ende, utilizaremos esta mejora del tavg para predecir nuevos datos.

```{r message=FALSE, warning=FALSE}
gr_quadratic_ecuation_model
gr_bike_uses_tavg_workday
```

Mediante este último cuadro, podemos evidenciar la similitud relativa que presenta el modelo con el comportamiento real de los datos.

#### Conclusión

------------------------------------------------------------------------

## CLASIFICACIÓN

#### Problema

El objetivo de este ejercicio es desarrollar un clasificador de noticias en "reales" o "fake-news". A partir de 3 predictores definidos: `title_has_excl, negative y title_words`

#### Solución

Comenzamos visualizando las variables predictoras para ver si pueden sesr útiles para clasificar las noticias en "reales" vs. "fake-news".

```{r}
table_fakenews_excl

gr_negative_title_words
```

Notamos que las variables mencionadas tienen cierta habilidad para predecir si una noticia es real o fake. A partir de este gráfico, observamos una notoria tendencia en la veracidad de las noticias: a medida que el porcentaje de palabras negativas en los títulos y la cantidad de palabras que lo componen también es menor, hay una mayor concentración de noticias reales. En el resto de los cuadrantes observados en el gráfico, existe una mayor predominancia de noticias falsas.

### Modelo de Árboles de Decisión

Para nuestro modelo de árboles de decisión, debemos hallar el minsplit que mejor predice la variable type

```{r}
v_accuracy_prom_tree
```

Vemos que para varios testeos un minsplit con valor 28, fue el que mejor predijo en promedio.

#probar con mas tests y ver otras variables (investigar rpart.control())

```{r}
rpart.plot(tree_model)
```

#PONER EL ACCURACY Y CREAR LA MATRIZ DE CONFUSION

```{r}
table_matriz_de_confusion_tree

v_accuracy_prom_tree[1,]
```

### Modelo de K-NN

Para nuestro modelo de k-nn, debemos hallar el k que mejor predice la variable type

```{r}
v_accuracy_prom_knn
```

Vemos que para 15 testeos un k con valor 31, fue el que mejor predijo en promedio.

#probar con mas tests y ver otras variables (investigar rpart.control())

#agregar un geom_point para mostrar las predicciones

#agregar matriz de confusion y accuracy

```{r}

```

#### Testeo

Supongamos que se publica un nuevo artículo que tiene un título de 15 palabras sin signos de exclamación y el 6% de sus palabras tienen connotaciones negativas. Calcular la probabilidad de que el artículo sea "fake-news".

Probemos con nuestos modelos la probabilidad de que sea real vs fake.

```{r}

prediction_tree_model

prediction_knn_model
```

#### Conclusión
